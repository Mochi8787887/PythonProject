文章參考: https://ithelp.ithome.com.tw/articles/10203371

一. 深度學習常遇到的問題是：難以概括看不見的數據。
1. 神經網絡具有大量的權重雖然可以很好地抓出訓練集中的特徵，卻也容易導致過度擬合(Overfitting)的現象。
2. 碰見資料不均的情況（例如在某些類別中沒有足夠的數據），雖然模型在訓練集的表現佳，但在測試集（即從未見過的數據）可能表現極差，表示此模型沒有足夠泛化（generalization）
※最佳化（optimization） 的目的是找到最小化訓練集損失的最佳參數
※泛化（generalization） 則是說明了模型對看不見的數據的行為。


二. 避免 Overfitting 的方法：目的是希望讓模型能夠更穩健，提高泛化程度。
1. 搜集更多資料——————資料分析任務中，更多的數據往往能提高模型的準確性，且減少過度擬合的可能性。
2. Dropout——————减少神經網絡的層數、神經元個數等方式，可以限制神經網絡的擬合能力。
3. Early Stopping——————每一個 epoch 結束時計算驗證集（validation data）的準確率，【當準確率不再提高就停止訓練】。
4. Data augmentation——————增加本身數據的多樣性
5. Weight Decay(較複雜)——————原理是在 cost function 的後面增加一個懲罰項（代表對某些參數做一些限制）
6. 簡化模型複雜——————讓模型更輕，訓練、運行更快
